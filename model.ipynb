{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28C1pVU9FeNI"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUhaBQ4LFZs2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime, os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import tensorflow as tf\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogJAQYoUCkYi"
   },
   "outputs": [],
   "source": [
    "RNG_SEED = 517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrJ6vxCeFZs8"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvPzH_4iFZs9"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(year):\n",
    "    data = pd.read_stata(\"data/ed\" + str(year) + \"-stata.dta\", convert_categoricals=False)\n",
    "    return data\n",
    "\n",
    "years = [(2009,), (2010,), (2011,), (2012,), (2013,), (2014,), (2015,), (2016,), (2017,), (2018,), (2019,), (2020,)]\n",
    " \n",
    "final_data = [None] * len(years)\n",
    "\n",
    "with Pool(processes=len(years)) as pool:\n",
    "    df_list = [pool.apply_async(prepare_dataset, p) for p in years]\n",
    "    for i in range(0, len(years)):\n",
    "        final_data[i] = df_list[i].get()\n",
    "\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XsqzJqkYNGJ"
   },
   "outputs": [],
   "source": [
    "# Fill missing meds\n",
    "for i in range(1, 30):\n",
    "  name = 'MED' + str(i)\n",
    "  for df in final_data:\n",
    "    if name not in df:\n",
    "      df[name] = -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tOrkyxs-5H1"
   },
   "outputs": [],
   "source": [
    "data = pd.concat(final_data)\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDqmaBajFZs-"
   },
   "outputs": [],
   "source": [
    "meds_types = {}\n",
    "for i in range(1, 30):\n",
    "  name = 'MED' + str(i)\n",
    "  meds_types[name] = 'int32'\n",
    "\n",
    "data = data.astype(meds_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFzgbeHwast7"
   },
   "source": [
    "# Descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKgcQ-SKFZs-"
   },
   "source": [
    "## Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRfWA98MED9H"
   },
   "outputs": [],
   "source": [
    "icd10_orpha = {\n",
    "    '5819-': 34145,\n",
    "    'N04-': 69061,\n",
    "    'N05-': 28588,\n",
    "    '5839-': 567544,\n",
    "    'N059': 567544, # Not exactly, the etiology isn't known yet\n",
    "    'N119': 93111, # Not exactly, the etiology isn't known yet\n",
    "    'C64-': 319276,\n",
    "    '1899-': 319276,\n",
    "    'C649': 319276,\n",
    "    'E72-': 213,\n",
    "    'E834': 2196\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Gosh7sDFZs_"
   },
   "outputs": [],
   "source": [
    "data[\"RISK\"] = 0\n",
    "data[\"FINALDIAG\"] = \"0\"\n",
    "\n",
    "for code in icd10_orpha:\n",
    "  bool_arr = data[\"HDDIAG1\"].str.match(code) | data[\"HDDIAG\"].str.match(code) | data[\"HDDIAG2\"].str.match(code) | data[\"HDDIAG3\"].str.match(code) | data[\"HDDIAG4\"].str.match(code) | data[\"HDDIAG5\"].str.match(code)\n",
    "  data.loc[bool_arr, \"RISK\"] = 1\n",
    "  data.loc[bool_arr, \"FINALDIAG\"] = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1T0rFrkWWF6"
   },
   "outputs": [],
   "source": [
    "# Remove metadata about the event\n",
    "data.drop(columns=['VMONTH', 'VDAYR', 'ARRTIME', 'WAITTIME', 'AGEDAYS', 'AGER', 'VYEAR', 'YEAR'], errors='ignore', inplace=True)\n",
    "# Remove metadata regarding finances\n",
    "data.drop(columns=['NOPAY', 'PAYPRIV', 'PAYMCARE', 'PAYMCAID', 'PAYWKCMP', 'PAYSELF', 'PAYNOCHG', 'PAYOTH', 'PAYDK', 'PAYTYPER'], errors='ignore', inplace=True)\n",
    "# Remove preprocessed meta that the model will figure out\n",
    "data.drop(columns=['NOCHRON', 'TOTCHRON', 'DIAGSCRN', 'TOTDIAG', 'PROC', 'TOTPROC'], errors='ignore', inplace=True)\n",
    "# Remove random data\n",
    "data.drop(columns=['index', 'BLANK1', 'BLANK2', 'BLANK3', 'BLANK4', 'SURGDAY', 'RFV13D', 'RFV23D', 'RFV33D', 'RFV43D', 'RFV53D'], errors='ignore', inplace=True)\n",
    "# Remove exit data\n",
    "data.drop(columns=['NUMGIV', 'HDSTAT', 'ADISP'], errors='ignore', inplace=True)\n",
    "# Drop exit medication\n",
    "data = data.loc[:,~data.columns.str.startswith('GPMED')]\n",
    "data = data.loc[:,~data.columns.str.startswith('DRUGID')]\n",
    "data = data.loc[:,~data.columns.str.startswith('PRESCR')]\n",
    "data = data.loc[:,~data.columns.str.startswith('CONTSUB')]\n",
    "data = data.loc[:,~data.columns.str.startswith('COMSTAT')]\n",
    "data = data.loc[:,~data.columns.str.startswith('RX')]\n",
    "# Drop hospital coding\n",
    "data.drop(columns=['HOSPCODE', 'PATCODE', 'EMRED', 'HHSMUE', 'EHRINSE', 'EDPRIM', 'EDINFO', 'OBSCLIN', 'OBSSEP', 'OBSPHYSED', 'OBSHOSP', \n",
    "'OBSPHYSOT', 'OBSPHYSUN', 'BOARD', 'BOARDHOS', 'AMBDIV', 'TOTHRDIVR', 'REGDIV', 'ADMDIV', 'INCSHX', 'INCPHYS', 'EXPSPACE', 'BEDREG', 'KIOSELCHK', \n",
    "'CATRIAGE', 'IMBED', 'ADVTRIAGE', 'PHYSPRACTRIA', 'FASTTRAK', 'EDPTOR', 'DASHBORD', 'RFID', 'WIRELESS', 'ZONENURS', 'POOLNURS', 'SURGDAY',\n",
    "'BEDCZAR', 'BEDDATA', 'HLIST', 'HLISTED', 'EMEDRES', 'REGION', 'MSA', 'SETTYPE', 'CSTRATM', 'CPSUM', 'PATWT', 'EDWT', 'ADVTRIAG', 'MED'], errors='ignore', inplace=True)\n",
    "\n",
    "# Drop diags\n",
    "data = data.loc[:,~data.columns.str.startswith('HDDIAG')]\n",
    "data = data.loc[:,~data.columns.str.startswith('DIAG')]\n",
    "data = data.loc[:,~data.columns.str.startswith('PRDIAG')]\n",
    "\n",
    "# Drop bad columns\n",
    "data.replace(\"\", np.NaN, inplace=True)\n",
    "data.dropna(how='any', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BaUEw1mFZs_"
   },
   "outputs": [],
   "source": [
    "features = ['TEMPF', 'PULSE', 'RESPR', 'BPSYS', 'BPDIAS', 'POPCT']\n",
    "vcount = 0\n",
    "for f in features:\n",
    "  vcount = vcount + data[f].value_counts()[-9]\n",
    "  data[f].replace(-9, np.NaN, inplace=True)\n",
    "  data[f].replace(998, np.NaN, inplace=True)\n",
    "\n",
    "data = data.interpolate(method='linear', limit_direction ='forward')\n",
    "data = data.reset_index()\n",
    "\n",
    "excluded_indices = data.loc[data['RISK'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc-IhA8lFZtB"
   },
   "source": [
    "## Prepare data for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfnEHR3pFZtC"
   },
   "source": [
    "### Medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "118g4lEpFZtC"
   },
   "outputs": [],
   "source": [
    "med_list = []\n",
    "for i in range(1, 30):\n",
    "    med_list.append('MED' + str(i))\n",
    "\n",
    "meds = data[med_list].values.tolist()\n",
    "\n",
    "medication_binarizer = MultiLabelBinarizer(sparse_output=True)\n",
    "meds = pd.DataFrame.sparse.from_spmatrix(medication_binarizer.fit_transform(meds), columns=medication_binarizer.classes_,index=data.index).drop(columns=[-9]).add_prefix('med_').astype(np.float16)\n",
    "meds = meds.sparse.to_dense()\n",
    "\n",
    "del medication_binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbfH83s7rj_b"
   },
   "source": [
    "### Reason for visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZGYH4Jurlgs"
   },
   "outputs": [],
   "source": [
    "rfv_list = []\n",
    "for i in range(1, 4):\n",
    "    rfv_list.append('RFV' + str(i))\n",
    "\n",
    "rfvs = data[rfv_list].values.tolist()\n",
    "\n",
    "rfv_binarizer = MultiLabelBinarizer(sparse_output=True)\n",
    "rfvs = pd.DataFrame.sparse.from_spmatrix(rfv_binarizer.fit_transform(rfvs),columns=rfv_binarizer.classes_,index=data.index).drop(columns=[-9]).add_prefix('rfv_').astype(np.float16)\n",
    "rfvs = rfvs.sparse.to_dense()\n",
    "\n",
    "del rfv_binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qiU_i-krvC-"
   },
   "source": [
    "### Causes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iW3gaKArwoX"
   },
   "outputs": [],
   "source": [
    "cause_list = []\n",
    "for i in range(1, 4):\n",
    "    cause_list.append('CAUSE' + str(i))\n",
    "\n",
    "causes = data[cause_list].values.tolist()\n",
    "\n",
    "cause_binarizer = MultiLabelBinarizer(sparse_output=True)\n",
    "causes = pd.DataFrame.sparse.from_spmatrix(cause_binarizer.fit_transform(causes),columns=cause_binarizer.classes_,index=data.index).drop(columns=[-9, -8], errors='ignore').add_prefix('causes_').astype(np.float16)\n",
    "causes = causes.sparse.to_dense()\n",
    "\n",
    "del cause_binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbjQAJFGDkDe"
   },
   "source": [
    "### Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThKfdNLnFZtD"
   },
   "outputs": [],
   "source": [
    "scalers = {}  \n",
    "\n",
    "individual_ft = pd.DataFrame(index=data.index)\n",
    "\n",
    "individual_features = ['ETHUN', 'RESIDNCE', 'RACEUN', 'SEEN72', 'EPISODE', 'INJURY', 'PAINSCALE']\n",
    "\n",
    "for f in individual_features:\n",
    "    scalers[f] = LabelBinarizer()\n",
    "    temp_cp = pd.DataFrame(scalers[f].fit_transform(data[f]), columns=scalers[f].classes_, index=data.index).drop(columns=[-9, -8], errors='ignore').add_prefix(f + '_').astype(np.float16)\n",
    "    individual_ft = individual_ft.join(temp_cp)\n",
    "\n",
    "scalers['SEX'] = LabelBinarizer()\n",
    "individual_ft['SEX'] = scalers['SEX'].fit_transform(data['SEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQVaKH5ZymHc"
   },
   "outputs": [],
   "source": [
    "numeric_ft = pd.DataFrame(index=data.index)\n",
    "\n",
    "data[features] = data[features].replace(to_replace=-9.0, value=np.NaN)\n",
    "\n",
    "for f in features:\n",
    "    scalers[f] = StandardScaler()\n",
    "    t = np.asarray(data[f])\n",
    "    t = t.reshape(-1,1)\n",
    "    temp_cp = scalers[f].fit_transform(t)\n",
    "    temp_cp = pd.DataFrame(temp_cp, index=data.index, columns=[f])\n",
    "    \n",
    "    numeric_ft[f + '_-10'] = temp_cp[f] < -10\n",
    "    numeric_ft[f + '_-5'] = (temp_cp[f] < -5) & (temp_cp[f] >= -10)\n",
    "    numeric_ft[f + '_-3'] = (temp_cp[f] < -3) & (temp_cp[f] >= -5)\n",
    "    numeric_ft[f + '_-1'] = (temp_cp[f] < -1) & (temp_cp[f] >= -3)\n",
    "    numeric_ft[f + '_0'] = (temp_cp[f] < 1) & (temp_cp[f] >= -1)\n",
    "    numeric_ft[f + '_1'] = (temp_cp[f] > 1) & (temp_cp[f] <= 3)\n",
    "    numeric_ft[f + '_3'] = (temp_cp[f] > 3) & (temp_cp[f] <= 5)\n",
    "    numeric_ft[f + '_5'] = (temp_cp[f] > 5) & (temp_cp[f] <= 10)\n",
    "    numeric_ft[f + '_10'] = temp_cp[f] > 10\n",
    "\n",
    "numeric_ft.replace(to_replace=False, value=0, inplace=True)\n",
    "numeric_ft.replace(to_replace=True, value=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdaXgy-WEQnJ"
   },
   "source": [
    "### Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vL7z7K1zERt8"
   },
   "outputs": [],
   "source": [
    "lab_features = ['CEBVD', 'CHF', 'EDHIV', 'CBC', 'BUNCREAT', 'CARDENZ', 'ELECTROL', 'GLUCOSE', 'LFT', 'ABG', 'PTTINR', 'BLOODCX', 'BAC', 'OTHERBLD', 'CARDMON', 'EKG', 'HIVTEST', 'FLUTEST', 'PREGTEST', 'TOXSCREN', 'URINE', 'WOUNDCX', 'OTHRTEST', 'ANYIMAGE', 'XRAY', 'CATSCAN', 'CTHEAD', 'CTUNK', 'MRI', 'ULTRASND', 'OTHIMAGE', 'IVFLUIDS', 'SUTURE', 'INCDRAIN', 'NEBUTHER', 'BLADCATH', 'PELVIC', 'CENTLINE', 'CPR', 'ENDOINT', 'OTHPROC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDJLSJxWHN7g"
   },
   "outputs": [],
   "source": [
    "dist_features = ['OBSHOS', 'ADMITHOS', 'OBSDIS', 'TRANOTH', 'TRANPSYC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WyOhst6R3YR"
   },
   "source": [
    "### Autoencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmxmiFVL7FGE"
   },
   "outputs": [],
   "source": [
    "test_meds_positive = meds.iloc[excluded_indices.index]\n",
    "meds.drop(index=excluded_indices.index, inplace=True)\n",
    "\n",
    "test_meds_negative = meds.sample(frac=0.2, random_state=RNG_SEED)\n",
    "meds.drop(index=test_meds_negative.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZKuokT89hbH"
   },
   "outputs": [],
   "source": [
    "test_rfvs_positive = rfvs.iloc[excluded_indices.index]\n",
    "rfvs.drop(index=excluded_indices.index, inplace=True)\n",
    "\n",
    "test_rfvs_negative = rfvs.sample(frac=0.2, random_state=RNG_SEED)\n",
    "rfvs.drop(index=test_rfvs_negative.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqdPpTm67-iD"
   },
   "outputs": [],
   "source": [
    "test_causes_positive = causes.iloc[excluded_indices.index]\n",
    "causes.drop(index=excluded_indices.index, inplace=True)\n",
    "\n",
    "test_causes_negative = causes.sample(frac=0.2, random_state=RNG_SEED)\n",
    "causes.drop(index=test_causes_negative.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKa5jSr9xKJE"
   },
   "outputs": [],
   "source": [
    "lab_features = data.loc[:,lab_features]\n",
    "\n",
    "test_lab_features_positive = lab_features.iloc[excluded_indices.index]\n",
    "lab_features.drop(index=excluded_indices.index, inplace=True)\n",
    "\n",
    "test_lab_features_negative = lab_features.sample(frac=0.2, random_state=RNG_SEED)\n",
    "lab_features.drop(index=test_lab_features_negative.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wg2ZX5jdIdY4"
   },
   "outputs": [],
   "source": [
    "dist_features = data.loc[:,dist_features]\n",
    "\n",
    "test_dist_features_positive = dist_features.iloc[excluded_indices.index]\n",
    "dist_features.drop(index=excluded_indices.index, inplace=True)\n",
    "\n",
    "test_dist_features_negative = dist_features.sample(frac=0.2, random_state=RNG_SEED)\n",
    "dist_features.drop(index=test_dist_features_negative.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVVJ8EXH35R5"
   },
   "outputs": [],
   "source": [
    "test_numeric_positive = numeric_ft.iloc[excluded_indices.index]\n",
    "numeric_ft.drop(index=excluded_indices.index, inplace=True)\n",
    "\n",
    "test_numeric_negative = numeric_ft.sample(frac=0.2, random_state=RNG_SEED)\n",
    "numeric_ft.drop(index=test_numeric_negative.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnFZ-KYU3yeP"
   },
   "outputs": [],
   "source": [
    "training_df = meds.join(rfvs).join(causes).join(lab_features).join(numeric_ft).join(dist_features).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mWe4wKs_te-"
   },
   "outputs": [],
   "source": [
    "test_neg_df = test_meds_negative.join(test_rfvs_negative).join(test_causes_negative).join(test_lab_features_negative).join(test_numeric_negative).join(test_dist_features_negative)\n",
    "test_pos_df = test_meds_positive.join(test_rfvs_positive).join(test_causes_positive).join(test_lab_features_positive).join(test_numeric_positive).join(test_dist_features_positive)\n",
    "\n",
    "test_df = pd.concat([test_neg_df, test_pos_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGj4LSsXFZtF"
   },
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return K.mean(f1_val)\n",
    "\n",
    "def get_specificity(true, pred):\n",
    "    true = K.cast(true, 'float32')\n",
    "\n",
    "    ground_positives = K.sum(true, axis=0) + K.epsilon()       # = TP + FN\n",
    "    pred_positives = K.sum(pred, axis=0) + K.epsilon()         # = TP + FP\n",
    "    true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP\n",
    "    true_negatives = K.sum((1-true) * (1-pred), axis=0) + K.epsilon()  # = TN\n",
    "    false_positives = K.sum((1-true) * pred, axis=0) + K.epsilon()  # = FP\n",
    "    \n",
    "    precision = true_positives / pred_positives \n",
    "    recall = true_positives / ground_positives\n",
    "\n",
    "    specificity = true_negatives / (true_negatives + false_positives + K.epsilon())\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "    weighted_f1 = f1 * ground_positives / K.sum(ground_positives) \n",
    "    weighted_f1 = K.sum(weighted_f1)\n",
    "\n",
    "    return specificity\n",
    "\n",
    "def f1_weighted(true, pred): #shapes (batch, 4)\n",
    "    true = K.cast(true, 'float32')\n",
    "\n",
    "    ground_positives = K.sum(true, axis=0) + K.epsilon()       # = TP + FN\n",
    "    pred_positives = K.sum(pred, axis=0) + K.epsilon()         # = TP + FP\n",
    "    true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP\n",
    "        #all with shape (4,)\n",
    "    \n",
    "    precision = true_positives / pred_positives \n",
    "    recall = true_positives / ground_positives\n",
    "        #both = 1 if ground_positives == 0 or pred_positives == 0\n",
    "        #shape (4,)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "        #still with shape (4,)\n",
    "\n",
    "    weighted_f1 = f1 * ground_positives / K.sum(ground_positives) \n",
    "    weighted_f1 = K.sum(weighted_f1)\n",
    "\n",
    "    return 1 - weighted_f1 #for metrics, return only 'weighted_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "952hIbhKR3Fg"
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_count, layers):\n",
    "  input = keras.Input(shape=(input_count,))\n",
    "  features = input\n",
    "\n",
    "  i = 0\n",
    "  for h in layers:\n",
    "    features = keras.layers.Dense(h, activation='tanh', kernel_regularizer=regularizers.L1(0.0001))(features)\n",
    "    if (len(layers) - 1) / 2 == i:\n",
    "      encoder_dim = h\n",
    "      encoder = features\n",
    "    i = i + 1\n",
    "    features = keras.layers.BatchNormalization()(features)\n",
    "    #features = keras.layers.Dropout(0.1)(features)\n",
    "  decoded = keras.layers.Dense(input_count, activation='sigmoid', bias_initializer=keras.initializers.Constant(0.01))(features)\n",
    "  \n",
    "  full_model = keras.Model(input, decoded)\n",
    "  encoder = keras.Model(input, encoder)\n",
    "\n",
    "  encoded_input = keras.Input(shape=(encoder_dim,))\n",
    "\n",
    "  return full_model, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfspWxD-JWoa"
   },
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "   initial_lrate = 0.00001\n",
    "   k = 0.04\n",
    "   lrate = initial_lrate * math.exp(-k*epoch)\n",
    "   return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEKU8kBnPyr9"
   },
   "outputs": [],
   "source": [
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ed2qagYBsXi"
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "hsitoryfile = '/content/drive/MyDrive/Medicine/MRC/Models/history_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.csv'\n",
    "\n",
    "history_callback = keras.callbacks.CSVLogger(hsitoryfile)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "early_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "lrate = keras.callbacks.LearningRateScheduler(exp_decay)\n",
    "\n",
    "full_ae, full_encoder = create_autoencoder(training_df.shape[-1], [8000, 3000, 1500, 700, 300, 90, 300, 700, 1500, 3000, 8000])\n",
    "full_ae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001), run_eagerly=None,\n",
    "                loss=keras.losses.binary_crossentropy)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint('/content/drive/MyDrive/Medicine/MRC/Models/full-11y-90.best.keras', monitor='loss', save_best_only=True, mode='min')\n",
    "\n",
    "full_ae.fit(x=training_df, y=training_df, batch_size=64, epochs=1000, use_multiprocessing=True, workers=6, validation_split=0.12, callbacks=[ClearMemory(), lrate, checkpoint_callback, early_callback, history_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "817UuXneFZtH"
   },
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "\n",
    "  loss = gaussian_filter1d(history['loss'], sigma=2)\n",
    "\n",
    "  # Use a log scale to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, loss,\n",
    "               color=colors[n], label='Train '+label)\n",
    "  \n",
    "  if 'val_loss' in history:\n",
    "    val_loss = gaussian_filter1d(history['val_loss'], sigma=2)\n",
    "    plt.semilogy(history.epoch, val_loss,\n",
    "            color=colors[n], label='Validation '+label,\n",
    "            linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cp-Fp-zQc_B4"
   },
   "outputs": [],
   "source": [
    "test_predictions_baseline = full_ae.predict(test_pos_df, batch_size=64)\n",
    "test_neg_predictions_baseline = full_ae.predict(test_neg_df, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKWO6TibiN25"
   },
   "outputs": [],
   "source": [
    "bcount = len(test_neg_predictions_baseline)\n",
    "losses = np.zeros(bcount)\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False,\n",
    "    reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "for index in range(0, bcount):\n",
    "  losses[index] = bce(test_neg_predictions_baseline[index], test_neg_df.iloc[index])\n",
    "\n",
    "p_losses = bce(test_predictions_baseline, test_pos_df).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEhVIxKsEDhq"
   },
   "outputs": [],
   "source": [
    "positive_analysis = data.iloc[test_pos_df.index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpMrEi5gFnzm"
   },
   "outputs": [],
   "source": [
    "p_losses_df = pd.DataFrame(index=test_pos_df.index, data=p_losses)\n",
    "positive_analysis[\"SCORE\"] = p_losses_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lzTDeEvf5DA"
   },
   "outputs": [],
   "source": [
    "def generate_metrics(cutoff):\n",
    "  fp = (losses > cutoff).sum()\n",
    "  tn = len(test_neg_predictions_baseline) - fp\n",
    "\n",
    "  tp = (p_losses > cutoff).sum()\n",
    "  fn = len(test_predictions_baseline) - tp\n",
    "\n",
    "  prevalence = (tp + fn) / (tp + fn + tn + fp)\n",
    "  sensitivity = tp / (tp + fn)\n",
    "  fnr = fn / (tp + fn)\n",
    "  tnr = tn / (fp + tn)\n",
    "  fallout = fp / (fp + tn)\n",
    "  ppv = tp / (tp + fp)\n",
    "  npv = tn / (fn + tn)\n",
    "\n",
    "  lr_p = sensitivity / fallout\n",
    "  lr_n = fnr / tnr\n",
    "  dor = lr_p / lr_n\n",
    "  f_score = 2 * (ppv * sensitivity) / (ppv + sensitivity)\n",
    "\n",
    "  return prevalence, tnr, sensitivity, fallout, ppv, npv, lr_p, lr_n, dor, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bza1XjU4juit"
   },
   "outputs": [],
   "source": [
    "cutoff = 0.52\n",
    "\n",
    "prevalence, tnr, sensitivity, fallout, ppv, npv, lr_p, lr_n, dor, f_score = generate_metrics(cutoff)\n",
    "\n",
    "print(\"cutoff: \", cutoff)\n",
    "print(\"Prevalence \", prevalence)\n",
    "print(\"Specificity \", tnr)\n",
    "print(\"True positive rate \", sensitivity)\n",
    "print(\"False positive rate \", fallout)\n",
    "print(\"PPV \", ppv)\n",
    "print(\"NPV \", npv)\n",
    "print(\"LR+ \", lr_p)\n",
    "print(\"LR- \", lr_n)\n",
    "print(\"DOR \", dor)\n",
    "print(\"F-score \", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEvzdVG19IQP"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
    "\n",
    "sns.set(font_scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11VkIvaXuhRM"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=losses, label=\"Negative cases\", color='darkorange', kde=True, stat='density', cbar_kws={'edgecolor':'black'}, line_kws={'linewidth': 4})\n",
    "sns.histplot(data=p_losses, label=\"Positive cases\", color='darkblue', kde=True, stat='density', cbar_kws={'edgecolor':'black'}, line_kws={'linewidth': 4}, bins=25)\n",
    "\n",
    "plt.axvline(cutoff, color='black', label=\"Test cut-off\", linewidth=4)\n",
    "\n",
    "plt.legend(title = 'Samples')\n",
    "plt.xlabel('Test score')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZRtIEiodQ87"
   },
   "outputs": [],
   "source": [
    "ttest_ind(losses, p_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnWmX-GAExcd"
   },
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(8,8))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Absent Disease Detected (True Negatives): ', cm[0][0])\n",
    "  print('Absent Disease Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Case Missed (False Negatives): ', cm[1][0])\n",
    "  print('Case Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Cases : ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fM5Iszm4EyMU"
   },
   "outputs": [],
   "source": [
    "all_losses = np.concatenate((losses, p_losses), axis=None)\n",
    "all_labels = np.concatenate(([0] * len(losses), [1] * len(p_losses)), axis=None)\n",
    "\n",
    "plot_cm(all_labels, all_losses, cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1qqfKVyUWCn"
   },
   "source": [
    "# Voting system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGkP7mOPVlCT"
   },
   "outputs": [],
   "source": [
    "test_pos_latent = full_encoder.predict(test_pos_df, batch_size=50)\n",
    "test_neg_latent = full_encoder.predict(test_neg_df, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0i4fCh-USf5"
   },
   "outputs": [],
   "source": [
    "best_frac = 0.75\n",
    "cutoff = 0.996531000000044\n",
    "\n",
    "voters, testers = train_test_split(test_pos_latent, test_size=best_frac, random_state=RNG_SEED)\n",
    "\n",
    "pos_votes = cosine_similarity(testers, voters)\n",
    "neg_votes = cosine_similarity(test_neg_latent, voters)\n",
    "pos_mean = np.median(pos_votes, axis=1)\n",
    "neg_mean = np.median(neg_votes, axis=1) \n",
    "\n",
    "sns.histplot(data=neg_mean, label=\"Negative cases\", color='darkorange', kde=True, stat='density', cbar_kws={'edgecolor':'black'}, line_kws={'linewidth': 4})\n",
    "sns.histplot(data=pos_mean, label=\"Positive cases\", color='darkblue', kde=True, stat='density', cbar_kws={'edgecolor':'black'}, line_kws={'linewidth': 4}, bins=25)\n",
    "\n",
    "plt.legend(title = 'Samples')\n",
    "plt.xlabel('Test score')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pviObVj78K8"
   },
   "outputs": [],
   "source": [
    "ttest_ind(neg_mean, pos_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQ9Zov4zZkN8"
   },
   "outputs": [],
   "source": [
    "def generate_metrics(cutoff, pos_mean, neg_mean):\n",
    "  fp = (neg_mean > cutoff).sum()\n",
    "  tn = len(neg_mean) - fp\n",
    "\n",
    "  tp = (pos_mean > cutoff).sum()\n",
    "  fn = len(pos_mean) - tp\n",
    "\n",
    "  prevalence = (tp + fn) / (tp + fn + tn + fp)\n",
    "  sensitivity = tp / (tp + fn)\n",
    "  fnr = fn / (tp + fn)\n",
    "  tnr = tn / (fp + tn)\n",
    "  fallout = fp / (fp + tn)\n",
    "  ppv = tp / (tp + fp)\n",
    "  npv = tn / (fn + tn)\n",
    "\n",
    "  lr_p = sensitivity / fallout\n",
    "  lr_n = fnr / tnr\n",
    "  dor = lr_p / lr_n\n",
    "  f_score = 2 * (ppv * sensitivity) / (ppv + sensitivity)\n",
    "\n",
    "  return prevalence, tnr, sensitivity, fallout, ppv, npv, lr_p, lr_n, dor, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2K4Aq1-ZYaD"
   },
   "outputs": [],
   "source": [
    "cutoff = 0.996531\n",
    "\n",
    "prevalence, tnr, sensitivity, fallout, ppv, npv, lr_p, lr_n, dor, f_score = generate_metrics(cutoff,pos_mean,neg_mean)\n",
    "\n",
    "print(\"cutoff: \", cutoff)\n",
    "print(\"Prevalence \", prevalence)\n",
    "print(\"Specificity \", tnr)\n",
    "print(\"True positive rate \", sensitivity)\n",
    "print(\"False positive rate \", fallout)\n",
    "print(\"PPV \", ppv)\n",
    "print(\"NPV \", npv)\n",
    "print(\"LR+ \", lr_p)\n",
    "print(\"LR- \", lr_n)\n",
    "print(\"DOR \", dor)\n",
    "print(\"F-score \", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxvF0XLofd12"
   },
   "outputs": [],
   "source": [
    "all_losses = np.concatenate((neg_mean, pos_mean), axis=None)\n",
    "all_labels = np.concatenate(([0] * len(neg_mean), [1] * len(pos_mean)), axis=None)\n",
    "\n",
    "plot_cm(all_labels, all_losses, cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oETWckWJ1abO"
   },
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcyPPx2o2wjT"
   },
   "outputs": [],
   "source": [
    "X, Y = train_test_split(p_losses, test_size=best_frac, random_state=RNG_SEED)\n",
    "\n",
    "neg_comb = neg_mean + losses\n",
    "pos_comb = pos_mean + Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6N9pmyM347s"
   },
   "outputs": [],
   "source": [
    "def generate_metrics_combined(neg_mean, pos_mean, neg_loss, pos_loss):\n",
    "  fp = ((neg_mean > 0.996531000000044) | (neg_loss > 0.052)).sum()\n",
    "  tn = len(neg_mean) - fp\n",
    "\n",
    "  tp = ((pos_mean > 0.996531000000044) | (pos_loss > 0.052)).sum()\n",
    "  fn = len(pos_mean) - tp\n",
    "\n",
    "  prevalence = (tp + fn) / (tp + fn + tn + fp)\n",
    "  sensitivity = tp / (tp + fn)\n",
    "  fnr = fn / (tp + fn)\n",
    "  tnr = tn / (fp + tn)\n",
    "  fallout = fp / (fp + tn)\n",
    "  ppv = tp / (tp + fp)\n",
    "  npv = tn / (fn + tn)\n",
    "\n",
    "  lr_p = sensitivity / fallout\n",
    "  lr_n = fnr / tnr\n",
    "  dor = lr_p / lr_n\n",
    "  f_score = 2 * (ppv * sensitivity) / (ppv + sensitivity)\n",
    "\n",
    "  return prevalence, tnr, sensitivity, fallout, ppv, npv, lr_p, lr_n, dor, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeoEg5_X3-yO"
   },
   "outputs": [],
   "source": [
    "prevalence, tnr, sensitivity, fallout, ppv, npv, lr_p, lr_n, dor, f_score = generate_metrics_combined(neg_mean, pos_mean, losses, Y)\n",
    "\n",
    "print(\"Prevalence \", prevalence)\n",
    "print(\"Specificity \", tnr)\n",
    "print(\"True positive rate \", sensitivity)\n",
    "print(\"False positive rate \", fallout)\n",
    "print(\"PPV \", ppv)\n",
    "print(\"NPV \", npv)\n",
    "print(\"LR+ \", lr_p)\n",
    "print(\"LR- \", lr_n)\n",
    "print(\"DOR \", dor)\n",
    "print(\"F-score \", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e26Rdjaw5X0W"
   },
   "outputs": [],
   "source": [
    "all_losses = np.concatenate((((neg_mean > 0.996531000000044) | (losses > 0.052)), ((pos_mean > 0.996531000000044) | (Y > 0.052))), axis=None)\n",
    "all_labels = np.concatenate(([0] * len(neg_mean), [1] * len(pos_mean)), axis=None)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_losses)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "42502bd63c0268170c934ab7bc3455f73850b562e10dfbf416b8e9108a3e30b0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
